== Exercise 4 - Orchestrate your containers using Kubernetes

NOTE: This is an advanced exercise.

=== What you will learn
Participants will learn how to orchestrate a cluster of EAP containers from your Docker image using Kubernetes. 
Participants will also learn how to control how many replicas are created, and Kubernetes manages replication.

=== Prerequisites

* Participants should successfully have executed exercise 2
* Participatns should have cleaned up any running containers

[NOTE]
====
To clean up all the running container run the following command:
[source]
----
$ docker docker rm -f $(docker ps -aq)
----
====

=== Motivation

Docker containers are very powerful, especially when you link them together. However all those shell commands can get tiring to remember and and hard to maintain in a script. Additionally, you'll need to worry about getting the right docker containers on the right host, replicating containers and linking between containers on different hosts.

Luckily Kubernetes solves all of those problems. In this exercise we will create a cluster of Docker containers which are orchestrated by Kubernetes:

* Database container
** Postgres 9.x Database Server
* Application Server container
** Red Hat JBoss Enterprise Application Platform + Ticket Monster application

In Exercise 2 you have started the Docker container for JBoss EAP, and deployed Ticket Monster to it. In Exercise 3 you built on this, and added a container for PostgresSQL.

In Exercise 4 we'll orchestrate all the container we've created so far using Kubernetes. Each Docker container will be contained in a Kubernetes pod. Each pod can have multiple replicas. The pods talk to each other, and to the outside world using services.

Before we start implementing the cluster, let's review the basic Kubernetes concepts.

=== Kubernetes

kubernetes.io describes Kubernetes as:

[quote]
Kubernetes is an open source orchestration system for Docker containers. It handles scheduling onto nodes in a compute cluster and actively manages workloads to ensure that their state matches the users declared intentions. Using the concepts of "labels" and "pods", it groups the containers which make up an application into logical units for easy management and discovery.

While Docker defines the container format and builds and manages individual containers, an orchestration tool is needed to deploy and manage sets of containers. Kubernetes is a tool designed to orchestrate Docker containers. After building the container images you want, you can use a Kubernetes Master to deploy one or more containers in what is referred to as a pod. The Master pushes the containers in that pod to a Kubernetes Minion where the containers run.

For this example, both the Kubernetes Master and Minion are on the same VM which is running RHEL 7 Atomic host. Kubernetes relies on a set of service daemons to implement features of the Kubernetes Master and Minion. You need to understand the following about Kubernetes Masters and Minions:

Master: A Kubernetes Master is where you run kubectl commands to launch and manage containers. From the Master, containers are deployed to run on Minions.
Minion: A minion is a system providing the run-time environments for the containers.

Pod definitions are stored in configuration files (in yaml or json formats). Using the following procedure, you will set up a single RHEL 7 or RHEL Atomic system, configure it as a Kubernetes Master and Minion, use yaml files to define each container in a pod, and deploy those containers using Kubernetes (kubectl command).

Pods are the key thing you will define Kubernetes. Here's a complete list of the elements you define:

Services:: Creating a Kubernetes service lets you assign a specific IP address and port number to a label. Because pods and IP addresses can come and go with Kubernetes, that label can be used within a pod to find the location of the services it needs.
Replication Controllers:: By defining a replication controller, you can set not only which pods to start, but how many replicas of each pod should start. If a pod stops, the replication controller starts another to replace it.
Pods:: A pod loads one or more containers, along with options associated with running the containers.

The VM you are using has Kubernetes started by default, so you can just go ahead and use it!


Step 1 - Create a pod to run Ticket Monster in JBoss EAP::

With master and minion services running on the local system and the JBoss EAP container ready, you can now launch the containers using Kubernetes pods. Here are a few things you should know about that:
+
*Separate pods* - Although you can launch multiple containers in a single pod, by having them in separate pods each container can replicate multiple instances as demands require, without having to launch the other container.
+
*Everything runs locally* - Because each container is running with its port exposed on the local system, the containers don't need special service or networking configurations to be set up (e.g. for the application server to find the database server).
+
The following steps show how to launch and test the pod:
+
. Create a Web server pod file. Create a `jboss-eap.yaml` file that you will use to deploy the application server pod. Here is what it should contain:
+
----
apiVersion: v1beta3
id: jboss-eap-server-rc
kind: ReplicationController
metadata:
  name: jboss-eap-server
spec: 
  replicas: 1
  selector: 
    name: jboss-eap-server
  template:
    metadata:
      name: jboss-eap-server
      labels: 
        name: jboss-eap-server
        context: docker-jboss-eap-lab
    spec:
      containers: 
        - name: jboss-eap-server
          image: <your-alias> /jboss-eap-postgres-ticket-monster:1.0
          ports: 
            - containerPort: 9990
              hostPort: 9990
            - containerPort: 8080
              hostPort: 9080
            - containerPort: 9999
              hostPort: 9999
----
+
. Orchestrate the container with kubectl. With the yaml file in the current directory, run the following command to start the pod to begin running the container:
+
[source,numbered]
----
$ kubectl create -f jboss-eap.yaml
jboss-eap
----
+
[TIP]
====
If you get a connection error:
----
Error: Get http://localhost:8080/api/v1beta1/pods?namespace=default: dial tcp 127.0.0.1:8080: connection refused
----
Then try restart the Kubernetes API Server:
----
sudo systemctl restart kube-apiserver.service
----
====
+
. Check the container. If the container is running you should be able to see the pods with the kubectl command:
+
[source,numbered]
----
$ kubectl get pods
----
+
You should also be able to see the container using `docker ps`
+
. The database isn't up yet, so the app failed to deploy, but check that JBoss EAP is up by visiting <http://localhost:9080>.

Step 2 - Exploring Kubernetes::

Run the following commands to see the state of your Kubernetes services, pods and containers:
+
. Check out Kubernetes: Run the following commands to list information about the minion, replication controllers and running pods:
+
[source,numbered]
----
$ kubectl get minions
$ kubectl get minions
NAME        LABELS        STATUS
127.0.0.1   Schedulable   <none>    Ready
----
+
[source,numbered]
----
$ kubectl get pods
POD                      IP            CONTAINER(S)       IMAGE(S)                                      HOST                  LABELS                                               STATUS    CREATED
jboss-eap-server-3wevn   172.17.0.16   jboss-eap-server   pmuir/jboss-eap-postgres-ticket-monster:1.0   127.0.0.1/127.0.0.1   context=docker-jboss-eap-lab,name=jboss-eap-server   Running   About a minute
----
+
[source,numbered]
----
$ kubectl get rc
CONTROLLER         CONTAINER(S)       IMAGE(S)                                      SELECTOR                REPLICAS
jboss-eap-server   jboss-eap-server   pmuir/jboss-eap-postgres-ticket-monster:1.0   name=jboss-eap-server   1
----
+
[source,bash,numbered]
----
$ kubectl get service 
NAME            LABELS                                    SELECTOR   IP           PORT(S)
kubernetes      component=apiserver,provider=kubernetes   <none>     10.254.0.2   443/TCP
kubernetes-ro   component=apiserver,provider=kubernetes   <none>     10.254.0.1   80/TCP
----
+
. Check the container logs: Run the following command (replacing the last argument with the pod ID of your pods).
+
----
$ kubectl log <container-name>
...
----
+
TIP: There is good command line completion for Kubernetes, including completing container ids, so try doing `kubectl log <TAB>`...
+
Restart the pod:
+
----
$ kubectl delete pods,rc -l name=jboss-eap-server && kubectl create -f jboss-eap.yaml
----

Step 3 - Create pods for Postgres ::

Now that we've got the hang of using Kubernetes, lets go ahead and create a pod for Postgres and configure the Ticket Monster application container to use it.
+
Create the Postgres pod. The docker community has created a Postgres docker image, so we can just reuse that. Create a `postgres.yaml` file that you will use to deploy the application server pod. Here is what it should contain:
+
----
apiVersion: v1beta3
id: postgres-rc
kind: ReplicationController
metadata:
  name: postgres
spec: 
  replicas: 1
  selector: 
    name: postgres
  template: 
    metadata:
      name: postgres
      labels: 
        name: postgres
        context: docker-jboss-eap-lab
    spec: 
      containers: 
        - name: postgres
          image: postgres:9.4
          env: 
            - name: POSTGRES_PASSWORD
              value: UsW4fznqLmGRh6
          ports: 
            - containerPort: 5432
              hostPort: 5432
----
+
Create the Postgres service. Create a postgres-service.yaml file that you will use to deploy the database pod. Here is what it should contain:
+
----
apiVersion: v1beta3
kind: Service
metadata:
  name: postgres
spec:
  ports:
    - name: postgres
      port: 5432
      targetPort: 5432
  selector: 
    name: postgres
----
+
. Create the replication controller and the service with kubectl:
+
[source,bash,numbered]
----
$ kubectl create -f postgres.yaml
$ kubectl create -f postgres-service.yaml
----
+
Check that the postgres pod and service have come up using `kubectl get pods` and `kubectl get services`. If they show `Pending`, the images are still downloading or starting up. If they show `Running` then they are up.
+
Restart the JBoss EAP pod to have it connect to postgres:
+
----
$ kubectl delete pods,rc -l name=jboss-eap-server && kubectl create -f jboss-eap.yaml
----

As the database is now up the application should be working, check by visiting <http://localhost:9080/ticket-monster>.

Step 4 - Add some replicas and try killing them::

Edit the `jboss-eap.yaml` file and change the line `replicas: 1` to `replicas: 4`, and remove all the `hostPort` lines - if we try to bind 4 container ports to 9080 we'll get port conflcits!
+
Restart the JBoss EAP pod:
+
----
$  kubectl delete pods,rc -l name=jboss-eap-server && kubectl create -f jboss-eap.yaml
----

Run `kubectl get pods` and `docker ps` to see 4 JBoss EAP containers created.

Use the `docker stop` command you learnt about in Exercise 1 to try killing one of the Docker containers and see what Kubernetes does.

It's out of the scope of this lab to add a load balancer such as mod_cluster, but having done that you would then be able to use each of your replicas.

=== Summary
After the fourth exercise participant should start to feel comfortable with the basics of orchestrating containers using Kubernetes.

